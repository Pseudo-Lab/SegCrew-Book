
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Reading List: Weakly/Semi-supervised Learning based Segmentation &#8212; All about Segmentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../../_static/PseudoLab_logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/PseudoLab_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">All about Segmentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    [가짜연구소] All about Segmentation
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Semantic Segmentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch1/01_Semantic%20Segmentation.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch1/01_01_fullyconvNet.html">
   A. Fully Convolutional Network
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_01_01_fcn.html">
     FCN - CVPR 2015
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_01_02_DeepLabv3.html">
     DeepLab v3 - arXiv 2017
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_01_03_pspnet.html">
     PSPNet - CVPR 2017
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_01_04_encnet.html">
     EncNet - CVPR 2018
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch1/01_02_encodedecode.html">
   B. Convolutional encoder-decoder
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_02_01_unet.html">
     U-Net - arxiv 2015
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_02_03_DeconvNet.html">
     DeconvNet - ICCV 2015
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_02_02_segnet.html">
     SegNet - TPAMI 2017
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_02_01_multiresunet.html">
     MultiResUNet - arxiv 2019
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch1/01_03_transformer.html">
   C. Transformer based method
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_03_01_SETR.html">
     SETR - CVPR 2021
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch1/01_03_02_Segformer.html">
     Segformer - NeurIPS 2021
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Instance Segmentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch2/02_Instance_Segmentation.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch2/02_01_SlidingWnd.html">
   A. Sliding Window based Method
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_01_01_InstanceFCN.html">
     InstanceFCN - ECCV 2016
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch2/02_02_DetectorBase.html">
   B. Detector based Method
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_02_01_YOLACT.html">
     YOLACT - ICCV 19
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_02_02_SOLO.html">
     SOLO - ECCV 20
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_02_03_SOLOv2.html">
     SOLOv2 - NeurIPS 2020
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_02_01_MaskRCNN.html">
     [Draft] Mask R-CNN - ICCV 2017
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_02_04_HTC.html">
     HTC - CVPR 2019
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch2/02_02_05_BCNet.html">
     BCNet - CVPR 2021
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Panoptic Segmentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch3/03_Panoptic%20Segmentation.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch3/03_01_Box.html">
   A. Box based method
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch3/03_01_01_PanopticFPN.html">
     PanopticFPN - CVPR 2019
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch3/03_01_02_DETR.html">
     DETR - ECCV 2020
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch3/03_02_Box_Free.html">
   B. Box-free Method
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch3/03_02_01_PanopticFCN.html">
     PanopticFCN - CVPR 2021
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch3/03_02_02_Max-DeepLab.html">
     MaX-DeepLab - CVPR 2021
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Weakly-supervised Segmentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch4/04_Weakly-supervised%20Segmentation.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/04_01_LearningPixelAffinity.html">
   A. Learning Pixel Affinity
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_01_01_AffinityNet.html">
     AffinityNet - CVPR 2018
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_01_02_IAL.html">
     IAL - IJCV 2020
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/04_02_AdversarialErasing.html">
   B. Adversarial Erasing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_02_01_AE-PSL.html">
     [Draft] AE-PSL - CVPR 2017
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_02_02_SeeNet.html">
     SeeNet - NeurIPS 2018
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_02_03_GCNet.html">
     GCNet - ICCV 2021
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_02_05_PuzzleCAM.html">
     PuzzleCAM - ICIP 2021
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch4/04_03_Attention.html">
   C. Self-Attention
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch4/04_03_01_SEAM.html">
     SEAM - CVPR 2020
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Semi-supervised Segmentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch5/05%20Semi-supervised%20Segmentation.html">
   Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch5/05_01_Consistency_reg.html">
   A. Consistency Regularization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/05_01_01_CCT.html">
     CCT - CVPR 2020
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/05_01_02_SemiContexAware.html">
     Semi-supervised Semantic Segmentation with Directional Context-aware Consistency - CVPR 2021
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch5/05_02_GAN.html">
   B. GAN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/05_02_01_Revisiting_CycleGAN.html">
     Revisiting CycleGAN for semi-supervised segmentation - 	arXiv:1908.11569
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch5/05_02_02_s4GAN.html">
     s4GAN - arXiv:1908.05724
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Appendix/DenseCRF.html">
   Tutorial: DenseCRF for segmentation task
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/Pseudo-Lab/SegCrew-Book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/Pseudo-Lab/SegCrew-Book/issues/new?title=Issue%20on%20page%20%2Fdocs/ch0/Survey-WeaklySemi.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/docs/ch0/Survey-WeaklySemi.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Reading List: Weakly/Semi-supervised Learning based Segmentation</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="reading-list-weakly-semi-supervised-learning-based-segmentation">
<h1>Reading List: Weakly/Semi-supervised Learning based Segmentation<a class="headerlink" href="#reading-list-weakly-semi-supervised-learning-based-segmentation" title="Permalink to this headline">#</a></h1>
<p><strong>2021</strong></p>
<ul class="simple">
<li><p>[ClassMix] ClassMix: Segmentation-Based Data Augmentation for Semi-Supervised Learning, WACV 21 (<a class="reference external" href="https://arxiv.org/pdf/2007.07936">paper</a>, <a class="reference external" href="https://github.com/WilhelmT/ClassMix">code</a>, review)</p></li>
<li><p>Semi-supervised Semantic Segmentation with Directional Context-aware Consistency (paper, code, review)</p></li>
</ul>
<p><strong>2020</strong></p>
<ul class="simple">
<li><p>[DMT] Semi-Supervised Semantic Segmentation via Dynamic Self-Training and Class-Balanced Curriculum, 2020 (<a class="reference external" href="https://arxiv.org/pdf/2004.08514">paper</a> <a class="reference external" href="https://github.com/voldemortX/DST-CBC">code</a>, review)</p></li>
<li><p>[PseudoSeg] PseudoSeg: Designing Pseudo Labels for Semantic Segmentation. ICLR 20 (<a class="reference external" href="https://arxiv.org/pdf/2010.09713">paper</a> <a class="reference external" href="https://github.com/googleinterns/wss">code</a>, review)</p></li>
<li><p>[CutMix]Semi-supervised semantic segmentation needs strong, varied perturbations. BMVC 20 (<a class="reference external" href="https://arxiv.org/pdf/1906.01916">paper</a> <a class="reference external" href="https://github.com/Britefury/cutmix-semisup-seg">code</a>, review)</p></li>
<li><p>[GCT] Guided Collaborative Training for Pixel-wise Semi-Supervised Learning ECCV 20 (<a class="reference external" href="https://arxiv.org/pdf/2008.05258">paper</a> <a class="reference external" href="https://github.com/ZHKKKe/PixelSSL">code</a>, review)</p></li>
<li><p>[Three-stage] A Three-Stage Self-Training Framework for Semi-Supervised Semantic Segmentation. CVPR 20 (<a class="reference external" href="https://arxiv.org/pdf/2012.00827">paper</a>, code, review)</p></li>
<li><p>[ShapeProp] Learning Saliency Propagation for Semi-Supervised Instance Segmentation, CVPR 20 (<a class="reference external" href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhou_Learning_Saliency_Propagation_for_Semi-Supervised_Instance_Segmentation_CVPR_2020_paper.pdf">paper</a>, <a class="reference external" href="https://github.com/ucbdrive/ShapeProp">code</a>, review)</p></li>
<li><p>[CCT] Semi-Supervised Semantic Segmentation with Cross-Consistency Training, CVPR 20 (<a class="reference external" href="https://arxiv.org/abs/2003.09005">paper</a>, <a class="reference external" href="https://github.com/yassouali/CCT">code</a>, review)</p></li>
<li><p>[SCN] Semi-Supervised Semantic Image Segmentation with Self-correcting Networks, CVPR 20 (<a class="reference external" href="https://arxiv.org/abs/1811.07073">paper</a>, review)</p></li>
<li><p>Structured consistency loss for semi-supervised semantic segmentation, arxiv 2020 (paper, code, review)</p></li>
<li><p>[DSRG] Semi-supervised semantic segmentation via strong-weak dual-branch network. In ECCV, 2020 (paper, code, review)</p></li>
<li><p>[Naive-student] Naive-student: Leveraging semi-supervised learning in video sequences for urban scene segmentation. In ECCV, 2020a (paper, code, review)</p></li>
<li><p>[MCIS_wsss] Guolei Sun, Wenguan Wang, Jifeng Dai, and Luc Van Gool. Mining cross-image semantics for weakly supervised semantic segmentation. In ECCV, 2020 (paper, <a class="reference external" href="https://github.com/GuoleiSun/MCIS_wsss">code</a>, review)</p></li>
<li><p>Yude Wang, Jie Zhang, Meina Kan, Shiguang Shan, and Xilin Chen. Self-supervised equivariant attention mechanism for weakly supervised semantic segmentation. In CVPR, 2020 (paper, code, review)</p></li>
<li><p>Fan, J., Zhang, Z., Tan, T.: Cian: Cross-image affinity net for weakly supervised semantic segmentation. In: AAAI (2020)</p></li>
<li><p>Semi-supervised segmentation based on error-correcting supervision (2020)</p></li>
<li><p>Knowledge embedded generative adversarial networks for semi-supervised scene parsing (2020)</p></li>
</ul>
<p><strong>2019</strong></p>
<ul class="simple">
<li><p>Revisting Cycle-GAN for semi-supervised segmentation (<a class="reference external" href="https://arxiv.org/abs/1908.11569">paper</a>, <a class="reference external" href="https://github.com/arnab39/Semi-supervised-segmentation-cycleGAN?utm_source=catalyzex.com">code</a>, review)</p></li>
<li><p>[s4GAN] Semi-Supervised Semantic Segmentation with High- and Low-level Consistency, TPAMI 19 (<a class="reference external" href="https://arxiv.org/abs/1908.05724">paper</a>, <a class="reference external" href="https://github.com/sud0301/semisup-semseg">code</a>, review)</p></li>
<li><p>[USSS] Universal Semi-Supervised Semantic Segmentation, ICCV 19 (<a class="reference external" href="https://arxiv.org/abs/1811.10323">pdf</a>, <a class="reference external" href="https://github.com/tarun005/USSS_ICCV19">code</a>, review)</p></li>
<li><p>[FickleNet] FickleNet: Weakly and Semi-Supervised Semantic Image Segmentation Using Stochastic Inference, CVPR 19 (<a class="reference external" href="https://arxiv.org/abs/1902.10421">paper</a>, code, review)</p></li>
<li><p>[IRNet] Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations, CVPR 19 (<a class="reference external" href="https://arxiv.org/abs/1904.05044">paper</a>, <a class="reference external" href="https://github.com/jiwoon-ahn/irn">code</a>, review)</p></li>
<li><p>Chunfeng Song, Yan Huang, Wanli Ouyang, and Liang Wang. Box-driven class-wise region masking and filling rate guided loss for weakly supervised semantic segmentation, 2019. (paper, code, review)</p></li>
<li><p>[OOA] Jiang, P.T., Hou, Q., Cao, Y., Cheng, M.M., Wei, Y., Xiong, H.K.: Integral object mining via online attention accumulation. In: ICCV (2019)</p></li>
<li><p>Shimoda, W., Yanai, K.: Self-supervised difference detection for weakly-supervised semantic segmentation. In: ICCV (2019)</p></li>
</ul>
<p><strong>2018</strong></p>
<ul class="simple">
<li><p>Xiaolin Zhang, Yunchao Wei, Jiashi Feng, Yi Yang, and Thomas Huang. Adversarial complementary learning for weakly supervised object localization. In CVPR, 2018.</p></li>
<li><p>[MDC Adversarial] Adversarial Learning for Semi-Supervised Semantic Segmentation, BMVC 18 (<a class="reference external" href="https://arxiv.org/abs/1806.04659">pdf</a>, <a class="reference external" href="https://github.com/hfslyc/AdvSemiSeg">code</a>, review)</p></li>
<li><p>[RDC] Revisiting Dilated Convolution: A Simple Approach for Weakly- and Semi-Supervised Semantic Segmentation, CVPR 18 (<a class="reference external" href="https://arxiv.org/abs/1805.04574">paper</a>, code, review)</p></li>
<li><p>[Dynamically Instantiated Network] Weakly- and Semi-Supervised Panoptic Segmentation, ECCV 18 (<a class="reference external" href="https://arxiv.org/abs/1808.03575">pdf</a>, <a class="reference external" href="https://github.com/qizhuli/Weakly-Supervised-Panoptic-Segmentation">code</a>, review)</p></li>
<li><p>[L-Net, P-Net] Transferable Semi-Supervised Semantic Segmentation. AAAI 18 (<a class="reference external" href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16348">paper</a>, code, review)</p></li>
<li><p>[AffinityNet] Learning Pixel-level semantic Affinity Image-level Labels for weakly Supervised Semantic Segmentation, CVPR 18 (paper, code, review)</p></li>
<li><p>[GAIN] Tell Me Where to Look Guided Attention Inference Network (paper, code, review)</p></li>
<li><p>[PSL] Object region mining with adversarial erasing: A simple classification to semantic segmentation approach. (paper, code, review)</p></li>
<li><p>Normalized cut loss for weakly-supervised cnn segmentation. In: CVPR (paper, code, review)</p></li>
<li><p>[SeeNet] Self-erasing network for integral object attention. In: NIPs</p></li>
<li><p>[MCOF] Xiang Wang, Shaodi You, Xi Li, and Huimin Ma. Weakly supervised semantic segmentation by iteratively mining common object features. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018 (paper, code, review)</p></li>
<li><p><strong>[DSRG] Huang, Z., Wang, X., Wang, J., Liu, W., Wang, J.: Weakly-supervised semantic segmentation network with deep seeded region growing. In: CVPR (2018) (<a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Huang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.pdf">paper</a>, code, review)</strong></p></li>
<li><p>Weifeng Ge, Sibei Yang, and Yizhou Yu. Multi-evidence filtering and fusion for multi-label classification, object detection and semantic segmentation based on weakly supervised learning. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018 (paper, code, review)</p></li>
<li><p>Y. Zou, Z. Yu, B. Vijaya Kumar, J. Wang, Unsupervised domain adaptation for semantic segmentation via class-balanced self-training, in: European Conference on Computer Vision, 2018 (paper, code, review)</p></li>
<li><p>Semi-supervised skin lesion segmentation via transformation consistent self-ensembling model (2018)</p></li>
</ul>
<p><strong>2017</strong></p>
<ul class="simple">
<li><p>Semi Supervised Semantic Segmentation Using Generative Adversarial Network. ICCV 17 (<a class="reference external" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Souly__Semi_Supervised_ICCV_2017_paper.pdf">paper</a>, code, review)</p></li>
<li><p>Two-phase learning for weakly supervised object localization. In ICCV, 2017. (paper, code, review)</p></li>
<li><p>[Hide-and-Seek] Hide-and-seek: Forcing a network to be meticulous for weakly-supervised object and action localization. In ICCV, 2017 (paper, code, review)</p></li>
<li><p>Discovering class-specific pixels for weakly-supervised semantic segmentation. In: BMVC (paper, code, review)</p></li>
<li><p>Exploiting saliency for object segmentation from image level labels. In: CVPR (paper, code, review)</p></li>
<li><p>Anna Khoreva, Rodrigo Benenson, Jan Hendrik Hosang, Matthias Hein, and Bernt Schiele. Simple does it: Weakly supervised instance and semantic segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017 (paper, code, review)</p></li>
<li><p>[WILDCAT] Thibaut Durand, Taylor Mordan, Nicolas Thome, and Matthieu Cord. WILDCAT: weakly supervised learning of deep convnets for image classification, pointwise localization and segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017 (paper, code, review)</p></li>
<li><p>Qibin Hou, Puneet Kumar Dokania, Daniela Massiceti, Yunchao Wei, Ming-Ming Cheng, and Philip Torr. Bottom-up top-down cues for weakly-supervised semantic segmentation. EMMCVPR, 2017.</p></li>
<li><p>Seunghoon Hong, Donghun Yeo, Suha Kwak, Honglak Lee, and Bohyung Han. Weakly supervised semantic segmentation using web-crawled videos. In CVPR, pages 3626–3635, 2017.</p></li>
</ul>
<p><strong>2016</strong></p>
<ul class="simple">
<li><p>Scribblesup: Scribble-supervised convolutional networks for semantic segmentation. CVPR (paper, code, review)</p></li>
<li><p>What’s the Point: Semantic Segmentation with Point Supervision. ECCV (2016) (paper, code, review)</p></li>
<li><p>Alexander Kolesnikov and Christoph H Lampert. Seed, expand and constrain: Three principles for weakly-supervised image segmentation. In ECCV, 2016</p></li>
<li><p>Tokmakov, P., Alahari, K., Schmid, C.: Weakly-supervised semantic segmentation using motion cues. In: ECCV (2016)</p></li>
</ul>
<p><strong>2015</strong></p>
<ul class="simple">
<li><p>Semi-Supervised Normalized Cuts for Image Segmentation, ICCV 16 (<a class="reference external" href="http://openaccess.thecvf.com/content_iccv_2015/papers/Chew_Semi-Supervised_Normalized_Cuts_ICCV_2015_paper.pdf">paper</a>, code, review)</p></li>
<li><p>Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation, ICCV 15 (<a class="reference external" href="https://arxiv.org/abs/1502.02734">pdf,</a> <a class="reference external" href="https://github.com/TheLegendAli/DeepLab-Context">code</a>, review)</p></li>
<li><p>Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation, NeurIPS 15 (<a class="reference external" href="https://arxiv.org/abs/1506.04924">paper</a>, code, review)</p></li>
<li><p>[SSHMT] SSHMT: Semi-supervised Hierarchical Merge Tree for Electron Microscopy Image Segmentation, ECCV 15 (<a class="reference external" href="https://arxiv.org/abs/1608.04051">paper</a>, code, review)</p></li>
<li><p>Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation. ICCV (paper, code, review)</p></li>
<li><p>Wei Zhang, Sheng Zeng, Dequan Wang, and Xiangyang Xue. Weakly supervised semantic segmentation for social images. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015 (paper, code, review)</p></li>
<li><p>Jia Xu, Alexander G. Schwing, and Raquel Urtasun. Learning to segment under various forms of weak supervision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015 (paper, code, review)</p></li>
<li><p>Deepak Pathak, Philipp Krahenbuhl, and Trevor Darrell. Constrained convolutional neural networks for weakly supervised segmentation. In ICCV, 2015</p></li>
<li><p>Pedro O Pinheiro and Ronan Collobert. From image-level to pixel-level labeling with convolutional networks. In CVPR, 2015.</p></li>
</ul>
<p><strong>2013</strong></p>
<ul class="simple">
<li><p>Semi-supervised Learning for Large Scale Image Cosegmentation, ICCV 13 (<a class="reference external" href="http://openaccess.thecvf.com/content_iccv_2013/papers/Wang_Semi-supervised_Learning_for_2013_ICCV_paper.pdf">paper</a>, code, review)</p></li>
<li><p>Semi-supervised Learning for Large Scale Image Cosegmentation, AAAI 13 (<a class="reference external" href="https://www.ijcai.org/Proceedings/13/Papers/279.pdf">paper</a>, code, review)</p></li>
</ul>
<p><em>Latest update: Oct, 2021</em></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/ch0"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By PseudoLab<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>