# [Draft] HTC - CVPR 2019

---

- **Title:** Hybrid Task Cascade for Instance Segmentation

- **Review By:** Hwigeon Oh

- **Edited by:** 

---

## Reference

- paper : [https://arxiv.org/abs/1901.07518](https://arxiv.org/abs/1901.07518)
- code : [https://github.com/open-mmlab/mmdetection/tree/master/configs/htc](https://github.com/open-mmlab/mmdetection/tree/master/configs/htc)

# 1. Introduction

## Cascade R-CNN
- https://arxiv.org/abs/1906.09756


- R-CNN 계열의 모델을 학습 할 때 각 anchor에 Positive/Negative class를 assign 하는 과정이 필요하다.

- 이 과정에서 threshold $u$를 사용하는데, 이 값에 따라 모델의 성능이 달라진다.

:::{figure-md} markdown-fig
<img src="pic/htc/20211013181442.png" alt="20211013181442" class="bg-primary mb-1" width="600px">

Relation between perfermance and Input IoU
:::

- `Input IoU`는 RPN의 output, `Output IoU`는 최종 prediction이다.


- 결과를 관찰해 봤을 때, 다음과 같은 insight를 얻을 수 있다:
	1. Input proposal이 정확할수록 Output도 정확하다.
	2. Input이 noisy한 경우에는 $u\approx\text{Input IOU}$인 경우가 그렇지 않은 경우보다 상대적인 성능이 높다.
	3. 각 $u$ 별로 성능 우위를 갖는 Input IoU들이 있다.
	4. (c)를 보면 $u$가 높다고 성능이 높은 것은 아님을 알 수 있다.
	5. 최종 prediction이 RPN의 proposal보다 더 정확하다.

:::{figure-md} markdown-fig
<img src="pic/htc/20211013181121.png" alt="20211013181121" class="bg-primary mb-1" width="300px">

Approach to improving performance
:::

- 따라서 Cascade R-CNN에서는:
	1. 다른 $u$를 가지고 학습한 여러 head를 이용
	2. RPN proposal보다 더 정확한 다른 head의 최종 prediction을 사용
하는 것으로 모델의 성능을 높히는 접근을 한다.

## Cascade Mask R-CNN
- 단순한 Cascade R-CNN + Mask R-CNN

:::{figure-md} markdown-fig
<img src="pic/htc/20211013182818.png" alt="20211013182818" class="bg-primary mb-1" width="600px">

Cascade Mask R-CNN
:::

- bbox AP + 3.5%, mask AP + 1.2%

- HTC의 저자는 이 부분에 발전의 여지가 있음을 캐치했다:
	1. Cascade R-CNN이 object detection에서 성능을 올릴 수 있었던 이유는 이전 step에서의 더욱 정확해진 box proposal을 사용했기 때문이다. (Cascaed refinement)
	2. 하지만 Cascade Make R-CNN에서 mask head가 이전 head로부터 얻는 것은 더욱 정확한 box proposal 뿐이다.
	3. 따라서 mask head 끼리의 information flow/connection을 만들어 주면 segmentation 성능을 올릴 수 있을 것이다.

## Scene context
- 저자는 scene context가 중요한 힌트를 제공한다고 말한다.
	- 근거를 ablation study를 통해서 제공한다.

- scene context를 이용하기 위해서 별도의 semantic segmentation bracn를 사용한다.


# 2. Related Work
(생략)


# 3. Hybrid Task Cascade

## Overview

:::{figure-md} markdown-fig
<img src="pic/htc/20211013184718.png" alt="20211013184718" class="bg-primary mb-1" width="600px">

The architecture evolution from Cascade Mask R-CNN to Hybrid Task Cascade
:::

- Nontations:
	- $\mathcal{P}$ : pooling operator (e.g. RoI Align)
	- $B_{t}$ : $t$-th stage box head
	- $M_{t}$ : $t$-th stage mask head
	- $\textbf{r}_{t}$ : $t$-th stage box prediction
	- $\textbf{m}_{t}$ : $t$-th stage mask prediction



## Cascade Mask R-CNN
- $\textbf{x}_{t}^{box} = \mathcal{P}(\textbf{x}, \textbf{r}_{t-1})$, $\textbf{r}_{t} = B_{t}(\textbf{x}_{t}^{box})$
- $\textbf{x}_{t}^{mask} = \mathcal{P}(\textbf{x}, \textbf{r}_{t-1})$, $\textbf{m}_{t} = M_{t}(\textbf{x}_{t}^{mask})$

- box prediction과 mask prediction이 parallel하다.
- 더 정확한, refinded box prediction으로부터 이득을 얻지 못하는 구조이다.


## Interleaved Execution
- $\textbf{x}_{t}^{box} = \mathcal{P}(\textbf{x}, \textbf{r}_{t-1})$, $\textbf{r}_{t} = B_{t}(\textbf{x}_{t}^{box})$
- $\textbf{x}_{t}^{mask} = \mathcal{P}(\textbf{x}, \textbf{r}_{t})$, $\textbf{m}_{t} = M_{t}(\textbf{x}_{t}^{mask})$

- refined box prediction을 활용하기 위해서 병렬적인 구조를 직렬적인 구조로 바꿨다.


## Mask Information Flow
- $\textbf{x}_{t}^{box} = \mathcal{P}(\textbf{x}, \textbf{r}_{t-1})$, $\textbf{r}_{t} = B_{t}(\textbf{x}_{t}^{box})$
- $\textbf{x}_{t}^{mask} = \mathcal{P}(\textbf{x}, \textbf{r}_{t})$, $\textbf{m}_{t} = M_{t}( \mathcal{F}(\textbf{x}_{t}^{mask}, \textbf{m}_{t-1}^{-}))$

- 이전 step의 mask prediction도 이용해서 현재 step의 prediction을 만든다. (information flow)
- $\textbf{m}_{t-1}^{-}$은 prediction 직전의 feature이다.
	- 아래 그림의 빨간 선

:::{figure-md} markdown-fig
<img src="pic/htc/20211013191211.png" alt="20211013191211" class="bg-primary mb-1" width="600px">

Architecture of multi-stage mask branches
:::
  
- $\mathcal{F}(\textbf{x}_{t}^{mask}, \textbf{m}_{t-1}^{-}) = \textbf{x}_{t}^{mask} + \mathcal{G}_{t}(\textbf{m}_{t-1}^{-})$


- Concat하지 않고 element-wise sum을 사용했다.

- box $\textbf{r}_{t-1}$와 $\textbf{r}_{t}$의 크기가 달라도 pooling 하기 때문에 3x3 conv에 padding을 주면 사이즈를 같게 유지할 수 있다.



## Spatial Contexts from Segmentation

- $\textbf{x}_{t}^{box} = \mathcal{P}(\textbf{x}, \textbf{r}_{t-1}) + \mathcal{P}(S(\mathbf{x}), \mathbf{r}_{t-1})$
- $\textbf{r}_{t} = B_{t}(\textbf{x}_{t}^{box})$
- $\textbf{x}_{t}^{mask} = \mathcal{P}(\textbf{x}, \textbf{r}_{t}) + \mathcal{P}(S(\mathbf{x}), \mathbf{r}_{t})$
- $\textbf{m}_{t} = M_{t}( \mathcal{F}(\textbf{x}_{t}^{mask}, \textbf{m}_{t-1}^{-}))$

$$\begin{aligned}
m_{\bar1}&=M_{\bar1}(x_t^{\text{mask}}), \\
m_{\bar2}&=M_{\bar1}(\mathcal{F}(x_t^{\text{mask}},\mathbf{m}_{\bar{1}})), \\ 
&\vdots \\
m_{\bar{t}-1}&=M_{\bar{t}}(\mathcal{F}(x_t^{\text{mask}},\mathbf{m}_{\bar{t}-2}))
\end{aligned}$$

- $S$는 segmentation head를 의미한다.

- foreground와 background의 더 명확한 구별을 위해서 spatial context를 주입한다.

- sementic segmentation을 수행하는 다른 branch를 만들고, 해당 branch의 feature를 이용하는 것으로 주입한다.

:::{figure-md} markdown-fig
<img src="pic/htc/20211013192425.png" alt="20211013192425" class="bg-primary mb-1" width="600px">

We introduce complementary contextual information by adding semantic segmentation branch.
:::

## Learning

- $\displaystyle L = \sum_{t=1}^{T} \alpha_{t}(L_{bbox}^{t} + L_{mask}^{t}) + \beta L_{seg}$

- $\displaystyle L_{bbox}^{t} (c_{i}, \textbf{r}_{t}, \hat{c}_{t}, \hat{\textbf{r}}_{t}) = L_{cls}(c_{t}, \hat{c}_{t}) + L_{reg}(\textbf{r}, \hat{\textbf{r}}_{t})$

- $L_{mask}^{t}(\textbf{m}_{t}, \hat{\textbf{m}}_{t}) = \text{BCE}(\textbf{m}_{t}, \hat{\textbf{m}}_{t})$

- $L_{seg} = \text{CE}(\textbf{s}, \hat{\mathbf{s}})$


<br>

# 4. Experiments

## Ablation Study

```{image} pic/htc/20211013194003.png
:alt: 20211013194003.png
:class: bg-primary mb-1
:align: center
```
