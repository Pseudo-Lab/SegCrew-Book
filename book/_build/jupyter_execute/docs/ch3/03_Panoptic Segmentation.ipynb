{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Introduction\n",
    "\n",
    ":::{figure-md} pano-fig\n",
    "<img src=\"pic/panoSeg3.PNG\" alt=\"pfpn2\" class=\"bg-primary mb-1\" width=\"600px\">\n",
    "\n",
    "Segmentation Tasks (source: [arXiv:2006.12567](https://arxiv.org/abs/2006.12567))\n",
    ":::\n",
    "\n",
    "- Panoptic Segmentation은 pixel level의 classification을 수행하는 semantic segmentation과 객체 단위 기반 classfication을 수행하는 instance segmentation을 통합한 task로 각 pixel을 배경에 해당하는 stuff와 객체(instance)에 해당하는 things class로 분류하는 task이다. \n",
    "- 즉 입력 영상의 각 pixel을 overlap되지 않은 class label로 분류하는 문제로 정의할 수 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measure\n",
    "\n",
    "- Panoptic Segmentation의 성능을 평가히기 위해 PQ(Panoptic Quality)를 사용한다. \n",
    "\n",
    "$$\n",
    "\\text{PQ}=\\frac{\\sum_{(p,q) \\in \\text{TP}}\\text{IoU}(p,q)}{|\\text{TP}|+\\frac{1}{2}|\\text{FP}|+\\frac{1}{2}|\\text{FN}|}\n",
    "$$\n",
    "\n",
    "- PQ를 계산하기 위해 먼저 Segment matching을 수행한 후 matching된 segment에 대해 PQ를 계산한다. 이때 GT와 predicted segment와의 match 여부는 IoU가 0.5 이상이고 가장 큰 IoU를 가지는 segment를 유일한 matched segment로 판정한다. \n",
    "- Metched segment를 계산한 후 TP(true positivie), FP(false positive)와 FN(false negative)를 구한다. 이는 {numref}`gt-fig`와 같이 나타낼 수 있다\n",
    "\n",
    ":::{figure-md} gt-fig\n",
    "<img src=\"pic/panoSeg2.png\" alt=\"pfpn2\" class=\"bg-primary mb-1\" width=\"500px\">\n",
    "\n",
    "GT and predicted panoptic segmentations of an image (source: arXiv:1801.00868)\n",
    ":::\n",
    "\n",
    "- PQ는 match되는 segment에 대한 평균 IoU에 match되지 않는 segment에 대한 페널티 $\\left(\\frac{1}{2}|FP| +\\frac{1}{2} |FN |\\right)$ 가 추가된 형태로 구성되어 있다.  PQ를 TP 항을 추가하여 분리하면 SQ(segmentation Quaility) 항과 RQ(recognition quality) 항의 곱으로 표현 가능하다. RQ는 널리 사용되는 F1 score로 해석할 수 있다. \n",
    "\n",
    "$$\n",
    "\\text{PQ}=\\underbrace{\\frac{\\sum_{(p,q) \\in \\text{TP}}\\text{IoU}(p,q)}{|\\text{TP}|}}_{\\text{SQ}}\\times \\underbrace{\\frac{\\text{TP}}{{|\\text{TP}|+\\frac{1}{2}|\\text{FP}|+\\frac{1}{2}|\\text{FN}|}}}_{\\text{RQ}}\n",
    "$$\n",
    "\n",
    "- PQ 계산시 void labels (unknown pixels 또는 out of class pixel)은 계산과정에서 제외한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# https://medium.com/analytics-vidhya/creating-a-dual-axis-pareto-chart-in-altair-e3673107dd14\n",
    "# https://altair-viz.github.io/user_guide/interactions.html\n",
    "# https://www.datacamp.com/tutorial/altair-in-python\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def GetGraphElement(chart_title, data, x_scale, y_scale, perf_measure, line_color = \"#000000\", point_color = \"#000000\", text_color = \"#000000\", text_y_pos = -10, textperf_y_pos=-20):\n",
    "    base = alt.Chart(data).encode(\n",
    "    x = alt.X(\"idx\", scale=alt.Scale(domain=x_scale),axis=None),\n",
    "    ).properties (\n",
    "    width = 600,\n",
    "    title = [chart_title]\n",
    "    )\n",
    "\n",
    "    line = base.mark_line(strokeWidth= 1.5, color = line_color).encode(\n",
    "        y=alt.Y(perf_measure, scale=alt.Scale(domain=y_scale),axis=alt.Axis(grid=True)),\n",
    "        color=alt.Color('type'),\n",
    "    )\n",
    "\n",
    "    points = base.mark_circle(strokeWidth= 3, color = point_color).encode(\n",
    "            y=alt.Y(perf_measure, scale=alt.Scale(domain=y_scale), axis=None),\n",
    "            tooltip = [alt.Tooltip('year'),\n",
    "            alt.Tooltip('nickname'),\n",
    "            alt.Tooltip(perf_measure),\n",
    "            alt.Tooltip('note'),],\n",
    "    )\n",
    "\n",
    "    point_nick = points.mark_text(align='center', baseline='middle', dy = text_y_pos,).encode(\n",
    "        y= alt.Y(perf_measure, scale=alt.Scale(domain=y_scale), axis=None),\n",
    "        text=alt.Text(perf_measure),\n",
    "        color= alt.value(text_color)\n",
    "    )\n",
    "    point_perf = points.mark_text(align='center', baseline='middle', dy = textperf_y_pos).encode(\n",
    "        y= alt.Y(perf_measure, scale=alt.Scale(domain=y_scale), axis=None),\n",
    "        text=alt.Text('nickname'),\n",
    "        color= alt.value(text_color)\n",
    "    )   \n",
    "\n",
    "    return base, line, points, point_nick, point_perf\n",
    "\n",
    "def description_test(pos_x, pos_y, text, color):\n",
    "    return alt.Chart({'values':[{}]}).mark_text(align = \"left\", baseline =\"top\").encode(\n",
    "        x = alt.value(pos_x),\n",
    "        y = alt.value(pos_y),\n",
    "        text = alt.value([text]),\n",
    "        color= alt.value(color)\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-861a374fb95d47698d0bf5cf58c24ded\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-861a374fb95d47698d0bf5cf58c24ded\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-861a374fb95d47698d0bf5cf58c24ded\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\", \"color\": \"#fde725\", \"strokeWidth\": 1.5}, \"encoding\": {\"color\": {\"field\": \"type\", \"type\": \"nominal\"}, \"x\": {\"axis\": null, \"field\": \"idx\", \"scale\": {\"domain\": [0, 7.0]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"grid\": true}, \"field\": \"PQ\", \"scale\": {\"domain\": [40.0, 55.0]}, \"type\": \"quantitative\"}}, \"title\": [\"Trend on Panoptic Quality (COCO Test-dev)\"], \"width\": 600}, {\"mark\": {\"type\": \"circle\", \"color\": \"#000000\", \"strokeWidth\": 3}, \"encoding\": {\"tooltip\": [{\"field\": \"year\", \"type\": \"quantitative\"}, {\"field\": \"nickname\", \"type\": \"nominal\"}, {\"field\": \"PQ\", \"type\": \"quantitative\"}, {\"field\": \"note\", \"type\": \"nominal\"}], \"x\": {\"axis\": null, \"field\": \"idx\", \"scale\": {\"domain\": [0, 7.0]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": null, \"field\": \"PQ\", \"scale\": {\"domain\": [40.0, 55.0]}, \"type\": \"quantitative\"}}, \"title\": [\"Trend on Panoptic Quality (COCO Test-dev)\"], \"width\": 600}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"dy\": -10}, \"encoding\": {\"color\": {\"value\": \"#000000\"}, \"text\": {\"field\": \"PQ\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"year\", \"type\": \"quantitative\"}, {\"field\": \"nickname\", \"type\": \"nominal\"}, {\"field\": \"PQ\", \"type\": \"quantitative\"}, {\"field\": \"note\", \"type\": \"nominal\"}], \"x\": {\"axis\": null, \"field\": \"idx\", \"scale\": {\"domain\": [0, 7.0]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": null, \"field\": \"PQ\", \"scale\": {\"domain\": [40.0, 55.0]}, \"type\": \"quantitative\"}}, \"title\": [\"Trend on Panoptic Quality (COCO Test-dev)\"], \"width\": 600}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"dy\": 20}, \"encoding\": {\"color\": {\"value\": \"#000000\"}, \"text\": {\"field\": \"nickname\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"year\", \"type\": \"quantitative\"}, {\"field\": \"nickname\", \"type\": \"nominal\"}, {\"field\": \"PQ\", \"type\": \"quantitative\"}, {\"field\": \"note\", \"type\": \"nominal\"}], \"x\": {\"axis\": null, \"field\": \"idx\", \"scale\": {\"domain\": [0, 7.0]}, \"type\": \"quantitative\"}, \"y\": {\"axis\": null, \"field\": \"PQ\", \"scale\": {\"domain\": [40.0, 55.0]}, \"type\": \"quantitative\"}}, \"title\": [\"Trend on Panoptic Quality (COCO Test-dev)\"], \"width\": 600}], \"data\": {\"name\": \"data-1dca03a993566a3cb449b42880e48213\"}, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-1dca03a993566a3cb449b42880e48213\": [{\"idx\": 1, \"type\": \"Panoptic Segmentation\", \"year\": 2019, \"nickname\": \"Panoptic-FPN\", \"PQ\": 40.9, \"note\": \"ResNet-101-FPN\"}, {\"idx\": 2, \"type\": \"Panoptic Segmentation\", \"year\": 2019, \"nickname\": \"UPSNet\", \"PQ\": 46.6, \"note\": \"ResNet-101-FPN\"}, {\"idx\": 3, \"type\": \"Panoptic Segmentation\", \"year\": 2020, \"nickname\": \"Axial-DeepLab\", \"PQ\": 44.2, \"note\": \"L-multi-scale\"}, {\"idx\": 4, \"type\": \"Panoptic Segmentation\", \"year\": 2020, \"nickname\": \"DETR\", \"PQ\": 45.1, \"note\": \"DETR-R101\"}, {\"idx\": 5, \"type\": \"Panoptic Segmentation\", \"year\": 2021, \"nickname\": \"PanopticFCN\", \"PQ\": 47.5, \"note\": \"DCN-101-FPN\"}, {\"idx\": 6, \"type\": \"Panoptic Segmentation\", \"year\": 2021, \"nickname\": \"MaX-DeepLab\", \"PQ\": 51.3, \"note\": \"MaX-L backbone\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"panoptic_trend.csv\", sep=\",\")\n",
    "\n",
    "seg_data = data.loc[data['type'] ==\"Semantic Segmentation\"]\n",
    "\n",
    "perf_measure = 'PQ'\n",
    "\n",
    "x_scale = [0,data['idx'].max()+1]\n",
    "y_scale = [((data[perf_measure].min()//5))*5,((data[perf_measure].max()//5)+1)*5]\n",
    "\n",
    "chart_title = \"Trend on Panoptic Quality (COCO Test-dev)\"\n",
    "\n",
    "base, line, points, point_nick, point_perf = GetGraphElement(chart_title, data, x_scale, y_scale, perf_measure, \n",
    "                                                            line_color = \"#fde725\", point_color = \"#000000\", text_color = \"#000000\", \n",
    "                                                            text_y_pos = -10, textperf_y_pos=20)\n",
    "(\n",
    "    line+points+point_nick+point_perf\n",
    ").resolve_scale(y = 'independent')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+++\n",
    "\n",
    "- 본 chapter에서는 panoptic segmentation 논문을 i) box based methods와 ii) box-free methods로 구분하여 리뷰하고 각 지금까지의 발전 현황과 개선방안에 대해 고찰한다.\n",
    "\n",
    "*Latest update: Nov. 10, 2022*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Panoptic_Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}