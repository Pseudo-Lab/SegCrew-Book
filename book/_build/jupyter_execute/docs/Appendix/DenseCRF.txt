import torch
model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=True)
# or
# model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)
model.eval()

# Download an example image from the pytorch website
import urllib
url, filename = ("https://github.com/pytorch/hub/raw/master/images/deeplab1.png", "deeplab1.png")
try: urllib.URLopener().retrieve(url, filename)
except: urllib.request.urlretrieve(url, filename)

# sample execution (requires torchvision)
from PIL import Image
from torchvision import transforms
input_image = Image.open(filename)
input_image = input_image.convert("RGB")
preprocess = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model

# move the input and model to GPU for speed if available
if torch.cuda.is_available():
    input_batch = input_batch.to('cuda')
    model.to('cuda')

with torch.no_grad():
    output = model(input_batch)['out'][0]

import numpy as np

VOC_CLASSES = [
    "background", "aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car",
    "cat", "chair", "cow", "diningtable", "dog", "horse", "motorbike", "person",
    "potted plant", "sheep", "sofa", "train", "tv/monitor",
]

VOC_COLORMAP = np.array([
    [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],
    [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],
    [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128], [0, 0, 0],
])

VOC_NUM_CLASSES = 21

import matplotlib.pylab as plt

def draw_voc_segmentation_result(img, pred):

    plt.figure(figsize=(20,20))

    #img = img.transpose(1, 2, 0)

    pred = pred.argmax(0).squeeze(0)

    print(pred.shape)
    pred = pred.data.cpu().numpy()
    bins = np.bincount(pred.flatten())
    label_value = np.nonzero(bins)[0]

    pred_mask = np.zeros(shape=(pred.shape[0],pred.shape[1] , 3), dtype='uint8')

    for n_class in range(VOC_NUM_CLASSES):
      pred_mask[np.where(pred>n_class)] = VOC_COLORMAP[n_class,:]

    plt.subplot(1,2,1)
    plt.title('Input Image', fontsize=16)
    plt.axis('off')
    ax=plt.gca()
    ax.get_xaxis().set_visible(False)
    ax.get_xaxis().set_visible(False)
    plt.imshow(img)

    plt.subplot(1,2,2)
    plt.title('Predict', fontsize=16)
    plt.axis('off')
    ax=plt.gca()
    ax.get_xaxis().set_visible(False)
    ax.get_xaxis().set_visible(False)
    plt.imshow(pred_mask)

    plt_handlers = []
    plt_titles = []
    for idx in label_value:

        if idx != 0:
          fc = VOC_COLORMAP[idx-1].astype('float')/255
          p = plt.Rectangle((0, 0), 1, 1, color=fc)
        
          plt_handlers.append(p)
          plt_titles.append('{value}: {name}'.format(value=idx, name=VOC_CLASSES[idx]))
        
    plt.legend(plt_handlers, plt_titles, loc='lower right', framealpha=.5)  

input_np = Image.fromarray(np.uint8(input_image))

draw_voc_segmentation_result(input_np, output)

!pip install git+https://github.com/lucasb-eyer/pydensecrf.git

import pydensecrf.densecrf as dcrf
from pydensecrf.utils import compute_unary, create_pairwise_bilateral, \
    create_pairwise_gaussian, softmax_to_unary, unary_from_softmax

import skimage.io as io

image = np.asarray(input_image)

dcrf_model = dcrf.DenseCRF(image.shape[0] * image.shape[1], VOC_NUM_CLASSES)

if torch.cuda.is_available():
    output_logit = output.to('cpu')

softmax = torch.nn.functional.softmax(output_logit, dim=0).numpy()

unary = unary_from_softmax(softmax)
unary = np.ascontiguousarray(unary)
dcrf_model.setUnaryEnergy(unary)


image = np.asarray(input_image)

feats = create_pairwise_gaussian(sdims=(10, 10), shape=image.shape[:2])

dcrf_model.addPairwiseEnergy(feats, compat=3,
                    kernel=dcrf.DIAG_KERNEL,
                    normalization=dcrf.NORMALIZE_SYMMETRIC)

feats = create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),
                                   img=image, chdim=2)

dcrf_model.addPairwiseEnergy(feats, compat=10,
                     kernel=dcrf.DIAG_KERNEL,
                     normalization=dcrf.NORMALIZE_SYMMETRIC)

#Q = d.inference(5)
Q, tmp1, tmp2 = dcrf_model.startInference()
for i in range(5):
    print("KL-divergence at {}: {}".format(i, dcrf_model.klDivergence(Q)))
    dcrf_model.stepInference(Q, tmp1, tmp2)

    res = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))
    output_tensor = torch.from_numpy(res)
    output_tensor = torch.nn.functional.one_hot(output_tensor, num_classes =VOC_NUM_CLASSES).permute(2, 0, 1)
    draw_voc_segmentation_result(input_np, output_tensor)
